import pandas as pd
from sklearn.preprocessing import StandardScaler

# √âtape 1 : Chargement du dataset brut
df = pd.read_csv('dataset_cleaned.csv')
print("‚úÖ Dataset charg√© avec succ√®s.")

# √âtape 2 : Remplacement des valeurs textuelles inutiles par NaN
df.replace(['not_applicable', 'unknown'], pd.NA, inplace=True)

# √âtape 3 : Conversion des colonnes en num√©riques si n√©cessaire
df = df.apply(pd.to_numeric, errors='ignore')

# √âtape 4 : Remplacement des NaN par la moyenne
df.fillna(df.mean(numeric_only=True), inplace=True)

# √âtape 5 : Remplacement des valeurs infinies
df.replace([float('inf'), float('-inf')], pd.NA, inplace=True)
df.fillna(df.mean(numeric_only=True), inplace=True)

# √âtape 6 : S√©lection des colonnes utiles
X = df[['src_ip', 'dst_ip', 'protocol', 'length', 'ttl', 'id', 'seq', 'request_reply']]
y = df['label']

# √âtape 7 : Encodage des colonnes cat√©gorielles
X = pd.get_dummies(X, columns=['src_ip', 'dst_ip', 'protocol', 'request_reply'], drop_first=True)

# √âtape 8 : Suppression des colonnes constantes
X = X.loc[:, X.nunique() > 1]

# √âtape 9 : V√©rification des NaN restants
X.dropna(axis=1, inplace=True)

# √âtape 10 : Normalisation des donn√©es
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# √âtape 11 : Cr√©ation du DataFrame final
df_cleaned = pd.DataFrame(X_scaled, columns=X.columns)
df_cleaned['label'] = y.values

# √âtape 12 : V√©rification finale des classes
print("\nüìä R√©partition des labels :")
print(df_cleaned['label'].value_counts())

# √âtape 13 : Sauvegarde dans un nouveau fichier CSV
df_cleaned.to_csv('dataset_cleaned_verified.csv', index=False)
print("\n‚úÖ Donn√©es nettoy√©es et normalis√©es sauvegard√©es dans 'dataset_cleaned_verified.csv'")
